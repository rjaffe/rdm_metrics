{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About this script:\n",
    "\n",
    "This script takes a csv file exported from the Google sheet titled 'Research IT Consulting Engagements Log.' \n",
    "('Consulting Log' tab) at:\n",
    "https://docs.google.com/spreadsheets/d/1BzVbvY0dpUhY3JxSXA6RPaLiLS5IRTRpdZVYrgf9zKI\n",
    "\n",
    "The script manipulates each row of the spreadsheet as a list. It uses list notation to refer to each column -- or what had been a column in the spreadsheet. For convenience, here are the list indices and headers associated with each column: \n",
    "\n",
    "| Index | Column header |\n",
    "| ------| ------------- |\n",
    "| [0]   | Start date |\n",
    "| [1]   | Consultant(s) |\n",
    "| [2]   | Client(s) |\n",
    "| [3]   | PI (Whose project is it?) |\n",
    "| [4]   | Department/ORU |\n",
    "| [5]   | Research Domain (e.g. Egyptology) |\n",
    "| [6]   | Position (grad, postdoc, faculty, undergrad, researcher) |\n",
    "| [7]   | Project type (dissertation, etc.) |\n",
    "| [8]   | Related course (if applicable) |\n",
    "| [9]   | Research IT service |\n",
    "| [10]  | Topic (uncontrolled) |\n",
    "| [11]  | Category (controlled) |\n",
    "| [12]  | Source |\n",
    "| [13]  | Hand-off and/or referral |\n",
    "| [14]  | Complexity (RDM) |\n",
    "| [15]  | Status |\n",
    "| [16]  | Link to details |\n",
    "| [17]  | Notes|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, sys\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import date, datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .csv file is containing the data is now generated from Google sheet (\"Research IT Consulting Engagement Log\"), \n",
    "then filtered for date, RIT Service (= 'RDM') and Category (= consultation-related categories: 'user support' + all categories beginning 'RDM')\n",
    "\n",
    "These are the parameters (arguments) that must be provided to the script:\n",
    "1. The filepath that points to the .csv file containing our data (which is now being generated from the \"Research IT Consulting Engagements Log.\")\n",
    "2. The filename of the .csv file.\n",
    "3. The 'report_period_descriptor' will be the text included in the first line of the report created by the script.\n",
    "4. The 'report_start' is the earliest consultation start date of the period covered by the report.\n",
    "5. The 'report_end' is the latest consultation start date of the period covered by the report\n",
    "\n",
    "You can load these from a file if you wish. The file should be a .py file that contains exactly the information shown below in lines 2 through 7. Place the file in the same folder as this Jupyter Notebook file, or provide the path to it in the cell magic command '%load.' (Remove the '#' before '%load' to run the command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Metrics_args/RDM_metrics_args-ALL-through-FY2018-Q1.py\n",
    "# These are the arguments provided to the script\n",
    "filepath = '/Users/rjaffe/Documents/RDM/RDM_Metrics/MetricsData/RITConsultingEngagementLog_Google-downloads/'\n",
    "filename = 'Research-IT-Consulting-Engagements-Log_20171019_1544PDT.csv'\n",
    "report_period_descriptor = 'the period from January 1, 2015 through September 30, 2017'\n",
    "report_start = '2015-01-01'\n",
    "report_end = '2017-09-30'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script utilizes dictionaries to store values for counting and to aggregate (\"roll up\"\") individual values \n",
    "under parent values. There are dictionaries for:\n",
    "1. The consultant involved in the consultation\n",
    "2. The department or ORU of the researcher/client\n",
    "3. The position or role of the researcher/client\n",
    "4. The category (RDM service area or lifecycle stage)\n",
    "5. The source of the consultation (or 'referral in'), rolled up to the organizational unit of the individual\n",
    "6. The referral (out), i.e., the person to whom the case was referred, rolled up to their organizational unit\n",
    "7. The complexity of the case\n",
    "8. The parent school, college or division of the researcher's/client's department or unit\n",
    "9. The College of Letters & Science as a whole (includes four divisions).\n",
    "\n",
    "We also use two other dictionaries to hold text values that vary by column:\n",
    "1. The labels used in our output for empty values\n",
    "2. The headings used in our output.\n",
    "\n",
    "Before we load the data file, let's initialize some configuration for the various dictionaries. The configuation is kept in a file currently named config_20171104.py, which we load using the cell magic command '%load.' (The file can be located in the same folder as the notebook file itself, or a path can be provided.) \n",
    "\n",
    "As new values are added to the Google Sheet, they should be added to the second value list within the correct dictionary here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load config_20171104.py\n",
    "# Positional elements (columns) with the following indices -- and only those elements, at present --\n",
    "# will be gathered and counted using a dictionary\n",
    "dictable_cols = [1, 4, 6, 11, 12, 13, 14]\n",
    "\n",
    "# In this version, we bring the \"dictable columns\" into dictionaries called:\n",
    "# • ccounter (consultants) \n",
    "# • dcounter (departments/ORUs)\n",
    "# • pcounter (position)\n",
    "# • cacounter (category)\n",
    "# • scounter (source)\n",
    "# • rcounter (referrals in and out) and \n",
    "# • cocounter (complexity).\n",
    "\n",
    "# Next we do modifications -- rolling up departmental values to their school, college or organizational parent; \n",
    "# L&S is first rolled up to its divisions, then aggregated as a college -- and store in new dictionaries: \n",
    "# • pacounter for values rolled-up by parent\n",
    "# • lscounter for Letters & Science divisions rolled up into a single total\n",
    "\n",
    "#Initialize dictionaries that we'll use later\n",
    "ccounter, dcounter, pcounter, cacounter, scounter, rcounter, cocounter, \\\n",
    "pacounter, lscounter = {},{},{},{},{},{},{},{},{}\n",
    "\n",
    "# let the data do the heavy lifting...everything is in this dict!\n",
    "ref_rollups = {\n",
    "    'lib': ['The Library', ['Harrison Dekker', 'Jamie Wittenberg', 'Susan Edwards', 'Steve Mendoza', 'Steven Mendoza',\n",
    "                            'Margaret Phillips', 'data-consult list (Library)', 'Brian Quigley', 'Library',\n",
    "                            'Data Storage/Sharing and the Social Sciences Working Group', 'Erik Mitchell',\n",
    "                            'Susan Powell', 'Anna Sackmann', 'David Eiffler', 'Yasmin Alnoamany', 'Stacy Reardon',\n",
    "                            'Celia Emmelhainz', 'Hilary Schiraldi', 'Amy Neeser']],\n",
    "    'css': ['Campus Shared Services - IT', ['Brett Larsen', 'Daniel Bass', 'Johnathon Kogelman',\n",
    "                                            'Johnathon Kogelman (CSS-IT)', 'CSS-IT', \n",
    "                                            'Referred by Johnathon Kogelman (CSS-IT)', \n",
    "                                            'request to Rick from Daniel Bass',\n",
    "                                            'email to Rick from Daniel Bass',\n",
    "                                            'CSS_IT (Jon Valmores)']],\n",
    "    'dlab': ['D-Lab', ['D-Lab Consulting List', 'D-Lab', 'Jon Stiles', 'Zawadi Rucks Ahidiana',\n",
    "                       'Rick Jaffe (via D-Lab Consulting web page)', 'dlab-consultants@lists.b.e', \n",
    "                       'd-lab consultants list', 'referred to D-Lab/Jon Stiles', 'D-Lab consultants list',\n",
    "                       'Rick at d-lab consulting Ticket #29430', 'D-Lab ticket#29433', 'Chris Hench (D-Lab)']],\n",
    "    'scf': ['Statistical Computing Facility', ['Chris Paciorek', 'Ryan Lovett']],\n",
    "    'brc': ['Berkeley Research Computing',\n",
    "            ['Patrick Schmitz', 'Aron Roberts', 'Aaron Culich', 'Jason Christopher', 'Kelly Rowland', 'Gary Jung',\n",
    "             'BRC Cloud Consulting', 'Jason Huff (Computational Genomics Resource Lab)',\n",
    "             'Berkeley Research Computing - Cloud', 'Yong Qin', 'Deb McCaffrey', 'email to BRC', \n",
    "             'brc@berkeley.edu']],\n",
    "    'dh': ['Digital Humanities @ Berkeley', ['Quinn Dombrowski', 'Camille Villa', 'Digital Humanities',\n",
    "                                             'Claudia Natalia Von Vacano']],\n",
    "    'rdm': ['RDM Consulting', ['researchdata@berkeley.edu', 'Rick Jaffe', 'Chris Hoffman', 'John B Lowe',\n",
    "                               'BRC Survey 2016 (Response to follow-up from Jamie)', 'email to Rick Jaffe', \n",
    "                               'Follow-up', 'Rick', 'follow up', 'email to Rick and Jason', \n",
    "                               'researchdata@b.e. (after browsing web site)', 'researchdata@b.e.', \n",
    "                               'researchdata@b.e', 'email to Rick from Jessica', 'email to Rick from Carla',\n",
    "                               'email to Rick from Laura', 'email to Rick from Phuong', 'email to Rick from Sarah',\n",
    "                               'Anna Sackman (RDM)', 'Email to Rick']],\n",
    "    'cdl': ['California Digital Library', ['Joan Starr', 'Stephanie Simms', \n",
    "                                           'Daniella Lowenberg (DASH), via Quinn Dombrowski']],\n",
    "    'ist': ['Information Services & Technology - API', ['Jennifer Bellenger', 'Jon Broshious', 'Ian Crew', 'Jon Hays',\n",
    "                                                        'bConnected', 'Michael Leefers', 'Alex Walton', \n",
    "                                                        'referred by Ian (bConnected)', \n",
    "                                                        'referred to Rick by Jennifer Bellenger (bConnected)',\n",
    "                                                        'Forwarded by Beth Muramoto (GSE) to Ian Crew (bConnected), who forwarded it in turn to researchdata@berkeley.edu',\n",
    "                                                        'bconnected']],\n",
    "    'micronet': ['Micronet', ['micronet', 'Micronet', 'micronet list', 'Micronet list']],\n",
    "    'iao': ['Industry Alliances Office', ['Nicole Hensley', 'Nicole Hensley (IAO/IPIRA)', 'Nicole Hensley (IAO)',\n",
    "                                         'email to Chris and Rick from Eric Giegerich',\n",
    "                                         'email from Nicole Hensley to Rick and Chris',\n",
    "                                         'Email from Nicole Hensley to Chris and to Rick']],\n",
    "    'ssw': ['School of Social Welfare', ['David Fullmer']],\n",
    "    'bids': ['Berkeley Institute for Data Science', ['BIDS']],\n",
    "    'brdo': ['Berkeley Research Development Office (VCRO)', ['Barbara Ustanko via Chris Hoffman']],\n",
    "    'lsit': ['Letters & Science IT', ['Michael Quan (Letters & Science IT)']],\n",
    "    'ais': ['Academic Innovation Studio', ['AIS drop-in (handled by Rick)']],\n",
    "    'musinf': ['Museum Informatics', ['BIDS Faire CSpace Portals poster']],\n",
    "    'rit': ['Research IT', ['research-it@berkeley.edu']]\n",
    "}\n",
    "\n",
    "org_rollups = {\n",
    "    'cchem': ['College of Chemistry', ['Department of Chemistry']],\n",
    "    'ced': ['College of Environmental Design', ['City and Regional Planning', 'Department of City & Regional Planning', 'Landscape Architecture & Environmental Planning']],\n",
    "    'citris':['Center for Information Technology Research in the Interest of Society', ['Center for Information Technology Research in the Interest of Society (CITRIS)']],\n",
    "    'cnr': ['College of Natural Resources', ['College of Natural Resources (CNR)', 'Department of Agricultural & Resource Economics (ARE)',\n",
    "                                             'Department of Environmental Science, Policy & Management (ESPM)',\n",
    "                                             'Department of Plant and Microbial Biology']],\n",
    "    'coe': ['College of Engineering', ['College of Engineering (CoE)','Department of Bioengineering',\n",
    "                                       'Department of Civil and Environmental Engineering',\n",
    "                                       'Department of Mechanical Engineering (ME)',\n",
    "                                       'Department of Nuclear Engineering',\n",
    "                                       'Division of Electrical Engineering/EECS',\n",
    "                                       'Institute for Environmental Science and Engineering']],\n",
    "    'dh':  ['Digital Humanities at Berkeley', ['Digital Humanities at Berkeley', 'Digital Humanities at Berkeley (DH)', 'Digital Humanities @ Berkeley']],\n",
    "    'eslib':['Ethnic Studies Library', ['Ethnic Studies Library']],\n",
    "    'gbsmrc':['Golden Bear Sleep and Mood Research Clinic', ['Golden Bear Sleep and Mood Research Clinic']],\n",
    "    'gse': ['Graduate School of Education', ['Graduate School of Education (GSE)']],\n",
    "    'gsj': ['Graduate School of Journalism', ['School of Journalism']],\n",
    "    'haas':['Haas School of Business', ['Haas School of Business']],\n",
    "    'intl':['International programs', ['International Computer Science Institute (ICSI)']],\n",
    "    'ist': ['Information Services & Technology', ['Information Services & Technology (IST)']],\n",
    "    'law': ['Berkeley Law', ['School of Law', 'Boalt Hall School of Law', 'Jurisprudence and Social Policy', 'Legal Studies Program']],\n",
    "    'lib': ['Library', ['Bancroft Library', 'Bancroft Library - Oral History Center', 'C.V. Starr East Asian Library', 'Ethnic Studies Library', 'Library']],\n",
    "    'ls':  ['College of Letters & Science - College-wide', ['College of Letters and Science (L&S)', 'D-Lab', 'Undergraduate Interdisciplinary Studies']],\n",
    "    'lsa': ['College of Letters & Science - Arts & Humanities', ['Department of Music', 'Department of Near Eastern Studies', 'Department of History of Art']],\n",
    "    'lsb': ['College of Letters & Science - Biological Sciences', \n",
    "                                            ['Department of Integrative Biology', \n",
    "                                             'Department of Molecular & Cell Biology',\n",
    "                                             'Department of Molecular & Cell Biology (MCB)']],\n",
    "    'lsm': ['College of Letters & Science - Math & Physical Sciences', \n",
    "                                            ['Department of Earth and Planetary Science (EPS)', \n",
    "                                             'Department of Physics', 'Department of Statistics']],\n",
    "    'lss': ['College of Letters & Science - Social Sciences', \n",
    "                                            ['Department of Anthropology',\n",
    "                                             'Department of Economics', 'Department of Geography', 'Department of History', \n",
    "                                             'Department of Political Science','Department of Psychology',\n",
    "                                             'Department of Sociology']],\n",
    "    'nat': ['National programs', ['Robert Wood Johnson Berkeley (Scholars in Health Policy Research Program)', 'Department of Economics / Robert Wood Johnson Berkeley (Scholars in Health Policy Research Program)']],\n",
    "    'noid':['Not specified', ['Unknown value', 'unidentified', 'Unassigned', 'Unknown department', 'Unknown status', 'Unspecified', 'Unknown division']],\n",
    "    'other':['Other', ['UCLA - Humanities CIO']],\n",
    "    'qb3': ['California Institute for Quantitative Biosciences (QB3)', ['CIRM/QB3 Shared Stem Cell Facility and High-Throughput Screening Facility']],\n",
    "    'sph': ['School of Public Health', ['School of Public Health', 'Division of Biostatistics/Public Health', \n",
    "                                        'UC Berkeley-UCSF Joint Medical Program']], \n",
    "    'ssw': ['School of Social Welfare', ['School of Social Welfare']],\n",
    "    'tchi':['Terner Center for Housing Innovation', ['Terner Center for Housing Innovation']],\n",
    "    'vcaf':['Vice Chancellor for Administration and Finance', ['Procurement Services - Supply Chain Management']],\n",
    "    'vcr': ['Vice Chancellor for Research Office', ['Berkeley Institute for Data Science (BIDS)', \n",
    "                                                    'Berkeley Seismological Lab',\n",
    "                                                    'Center for Effective Global Action (CEGA)',\n",
    "                                                    'Center for Studies in Higher Education',\n",
    "                                                    'Center for Race and Gender', 'Center for Study of Race and Gender',\n",
    "                                                    'Haas Institute for a Fair & Inclusive Society',\n",
    "                                                    'Human Evolution Research Center',\n",
    "                                                    'Industry Alliances Office (Vice Chancellor for Research)',\n",
    "                                                    'Institute of European Studies',\n",
    "                                                    'Institute of Human Development', \n",
    "                                                    'Institute for Research on Labor and Employment (IRLE)', \n",
    "                                                    '(California Policy Lab)',\n",
    "                                                    'Institute for the Study of Societal Issues',\n",
    "                                                    'Institute of Transportation Studies (ITS)',\n",
    "                                                    'Institute of Transportation Studies (ITS) - PATH',\n",
    "                                                    'Phoebe A. Hearst Museum of Anthropology', 'Hearst Museum of Anthropology',\n",
    "                                                    'UC Botanical Garden',\n",
    "                                                    'University of California Transportation Center']],\n",
    "    'vcue':['Vice Chancellor for Undergraduate Education', ['Berkeley Resource Center for Online Education (BRCOE)', 'Research IT']],\n",
    "}\n",
    "\n",
    "ls_rollup = {\n",
    "    'lsall': ['College of Letters & Science - All', ['College of Letters & Science - College-wide', \n",
    "             'College of Letters & Science - Arts & Humanities', 'College of Letters & Science - Biological Sciences', \n",
    "             'College of Letters & Science - Math & Physical Sciences', \n",
    "             'College of Letters & Science - Social Sciences']]\n",
    "}\n",
    "\n",
    "labels = ['Unassigned', 'Unknown department', 'Unknown status', '',  '', '', 'Unspecified', 'Unknown division',\n",
    "          'Consultation(s) without a partner',]\n",
    "\n",
    "orig_headings = ['Consultants, number of consults', 'Departments Served, number of engagements',\n",
    "            'Patron Status, number of patrons', 'RDM Lifecycle Category', 'Referrals In', 'Referrals Out',\n",
    "            'Consultation Complexity', 'Library Division, number of engagements',\n",
    "            'Organizational Partners, number of shared engagements' ]\n",
    "mod_headings = ['School, College or Office', 'School, College or Office, with L&S combined'] # for copied values\n",
    "all_headings = ['Consultants, number of consults', 'Departments Served, number of engagements',\n",
    "            'Patron Status, number of patrons', 'RDM Lifecycle Category', 'Referrals In', 'Referrals Out',\n",
    "            'Consultation Complexity', 'School, College or Office', 'School, College or Office, with L&S combined', \n",
    "            'Library Division, number of engagements',\n",
    "            'Organizational Partners, number of shared engagements']\n",
    "# List of dictionaries with modified values\n",
    "mod_dicts = [pacounter, lscounter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAN THE DATA\n",
    "\n",
    "With the dictionaries in place, the action begins...we read the .csv file and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO - Catch and handle missing arguments or errors in the arguments\n",
    "\n",
    "# Convert report_start and report_end arguments to datetime format\n",
    "reportstart = datetime.strptime(report_start, '%Y-%m-%d')\n",
    "reportend = datetime.strptime(report_end, '%Y-%m-%d')\n",
    "\n",
    "myrows = []\n",
    "\n",
    "# Read data into a list of lists, clean as required\n",
    "with open(filepath + filename) as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=\",\"):\n",
    "\n",
    "        # Filter Google sheet to include only RDM consultations during the desired period.\n",
    "        \n",
    "        # Remove header row (first header value is 'Start Date')\n",
    "        if row[0] == 'Start Date': continue\n",
    "\n",
    "        \n",
    "        # Convert start date values (first column) to datetime format and \\\n",
    "        # compare against report-start and report-end arguments. Skip if start date is not in report period range\n",
    "        startdate = datetime.strptime(row[0], '%Y-%m-%d')\n",
    "        if not reportstart <= startdate <= reportend: continue\n",
    "            \n",
    "        # Remove rows in which Research IT Service does not include RDM\n",
    "        RIT_service = row[9]\n",
    "        if not 'RDM' in RIT_service: continue\n",
    "\n",
    "        # Remove rows that are not consultations. For RDM, consultations were listed as 'User support' \\\n",
    "        # or (once) 'Library user support' until late February 2017. \\\n",
    "        # After that, they were coded as 'RDM [service area]', sometimes with multiple values listed\n",
    "        p = re.compile(r'^.*[Uu]ser support.*$')  # Matches 'User support' or 'Library user support'\n",
    "        p1 = re.compile(r'^.*(RDM)')  # Matches an instance of 'RDM [service area]'\n",
    "        category = row[11]\n",
    "        if not ((p.match(category)) or (p1.match(category))): continue\n",
    " \n",
    "\n",
    "        # Now clean, split multiple values, and aggregate (roll up) values as appropriate\n",
    "        \n",
    "        # Consultant(s), Department/ORU, Patron status, (RDM Lifecycle) Category, Source (aka referral in),\n",
    "        # Hand-off or referral (aka referral out), Consultation complexity: \\\n",
    "        # replace empty values with appropriate label\n",
    "        # NOTE: We didn't port Library division and Organizational partner fields to the Google sheet\n",
    "        \n",
    "        #for n, label in zip(config_20171104.dictable_cols, config_20171104.labels):  ## USE THIS IN PYCHARM\n",
    "        for n, label in zip(dictable_cols, labels):\n",
    "\n",
    "            # Fill in empty cells with appropriate label\n",
    "            if row[n] == '':\n",
    "                row[n] = label\n",
    "                    \n",
    "            # Remove trailing soft returns (i.e.,\\n) -- it's hard to control these in Google Sheets.\n",
    "            val = row[n]\n",
    "            suffix = '\\n'\n",
    "            if(val.endswith(suffix)):\n",
    "                val = val[:-1]\n",
    "                row[n] = val  # I don't completely trust this, but I don't seem to be losing any data!\n",
    "            \n",
    "            # make every cell into a list (some cells have new-line separated values)\n",
    "            row[n] = row[n].split('\\n')\n",
    "        # Replace individual names with the corresponding org name in Source (aka Referral In) and\n",
    "        # Hand-off or referral (aka Referral Out) fields\n",
    "        # (positional elements [12] and [13])\n",
    "        for n in [12, 13]:\n",
    "            ref_x = row[n]\n",
    "            row[n] = []  # Empty cell to ready it for being re-filled\n",
    "            for term in ref_x:\n",
    "                #for key in config_20171104.ref_rollups.keys():    ## USE THIS IN PYCHARM\n",
    "                for key in ref_rollups.keys():\n",
    "                    #if term in config_20171104.ref_rollups[key][1]:   ## USE THIS IN PYCHARM\n",
    "                    if term in ref_rollups[key][1]: \n",
    "                        #term = config_20171104.ref_rollups[key][0]    ## USE THIS IN PYCHARM\n",
    "                        term = ref_rollups[key][0]\n",
    "                        row[n].append(term)\n",
    "        myrows.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the number of consultations (number of rows gathered above) and determine how many have been resolved successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IGNORE THIS FOR NOW...WE HAVEN'T TRANSFERRED THE COMPLETED SIGNIFIER FROM DRUPAL TO THE GOOGLE SHEET.\n",
    "# PLUS, WE NEED TO GARDEN THE GOOGLE SHEET TO MARK COMPLETED CONSULTATIONS.\n",
    "\n",
    "# ***** COUNT THE DATA *****\n",
    "# Each row (list) represents a consulting engagement\n",
    "print('\\nIn %s, RDM Consulting provided %d consultations.' % (report_period_descriptor, (len(myrows))))\n",
    "\n",
    "# Count how many engagements are resolved successfully\n",
    "yesrows = []\n",
    "\n",
    "for r in myrows:\n",
    "    r15 = r[15]\n",
    "    if 'Resolved' in r15:\n",
    "        yesrows.append(r)\n",
    "\n",
    "#print('We reached a successful resolution in %d of those engagements.' % len(yesrows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we count and store the unique values in several of the erstwhile columns and print the totals to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather and count (subtotal) the values for consultant(s), department/oru, patron status, (RDM lifecycle) category,\n",
    "# source (referrals in), hand-off or referral (referrals out) and consultation complexity.\n",
    "# TODO: calculate values for library division and organizational partners fields\n",
    "\n",
    "#for i, n in enumerate(config_20171104.dictable_cols):   ## USE THIS IN PYCHARM\n",
    "for i, n in enumerate(dictable_cols):  # the i identifies heading to use when printing results to screen (below)\n",
    "    counter = Counter()\n",
    "    for row in myrows:\n",
    "        for z in row[n]:\n",
    "            counter[z] += 1\n",
    "        if n == 1:\n",
    "            ccounter.update(counter.most_common())\n",
    "        elif n == 4:\n",
    "            dcounter.update(counter.most_common())     \n",
    "        elif n == 6:\n",
    "            pcounter.update(counter.most_common())\n",
    "        elif n == 11:\n",
    "            cacounter.update(counter.most_common())\n",
    "        elif n == 12:\n",
    "            scounter.update(counter.most_common())\n",
    "        elif n == 13:\n",
    "            rcounter.update(counter.most_common())\n",
    "        else:\n",
    "            cocounter.update(counter.most_common())\n",
    "    \n",
    "    # Print results to screen\n",
    "    #print('\\n' + config_20171104.orig_headings[j] + ':')  # Use this in Pycharm or command-line invocation\n",
    "    print('\\n' + orig_headings[i] + ':')\n",
    "    for (k, v) in counter.most_common():\n",
    "        print(k + ': ' + str(v))\n",
    "    \n",
    "# Uncomment to view data structures and to debug        \n",
    "# print('\\n')\n",
    "# print(ccounter)\n",
    "# print('\\n')\n",
    "# print(dcounter)\n",
    "# print ('\\n')\n",
    "# print(pcounter)\n",
    "# print('\\n')\n",
    "# print(cacounter)\n",
    "# print('\\n')\n",
    "# print(scounter)\n",
    "# print('\\n')\n",
    "# print(rcounter)\n",
    "# print('\\n')\n",
    "# print(cocounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, modify the values and write to new dictionaries: roll-up department/ORU key/value pairs into schools, colleges and divisions, first with the divisions of the College of Letters & Science separated and then with the divisions all counted within the College. [TODO: Do the same for the divisions of the College of Engineering?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate (\"roll-up\") granular Department value into corresponding parent organization value\n",
    "\n",
    "for k, v in dcounter.items():\n",
    "    #for key in config_20171104.org_rollups.keys():    # Use this in Pycharm or command-line invocation\n",
    "    for key in org_rollups.keys():\n",
    "        #if k in config_20171104.org_rollups[key][1]:   # Use this in Pycharm or command-line invocation\n",
    "        if k in org_rollups[key][1]:         # No else to this if: org_rollup dict updated to include all keys (Depts)\n",
    "            #k = config_20171104.org_rollups[key][0]    # Use this in Pycharm or command-line invocation\n",
    "            k = org_rollups[key][0]\n",
    "            if k in pacounter.keys():\n",
    "                pacounter[k] = (pacounter[k] + v)\n",
    "            else:\n",
    "                pacounter[k] = v\n",
    "\n",
    "# Additionally, roll-up all Letters & Science in one L&S tally\n",
    "\n",
    "for k, v in pacounter.items():\n",
    "    #for key in config_20171104.ls_rollup.keys():    # Use this in Pycharm or command-line invocation\n",
    "    for key in ls_rollup.keys():\n",
    "        #if k in config_20171104.ls_rollup[key][1]:   # Use this in Pycharm or command-line invocation\n",
    "        if k in ls_rollup[key][1]:\n",
    "            #k = config_20171104.ls_rollups[key][0]    # Use this in Pycharm or command-line invocation\n",
    "            k = ls_rollup[key][0]\n",
    "            if k in lscounter.keys():\n",
    "                lscounter[k] = (lscounter[k] + v)  # L&S-All key added previously; add value to existing value\n",
    "            else:\n",
    "                lscounter[k] = v  # No other item rolled-up yet; add L&S-All key, assign value \n",
    "        else:\n",
    "            lscounter[k] = v  # key not in set of keys to be rolled up, guaranteed to be unique within this dict\n",
    "\n",
    "\n",
    "# # Print results to screen\n",
    "#for h, d in zip(config_20171104.mod_headings, config_20171104.mod_dicts):  # Use this in Pycharm or command-line invocation\n",
    "for h, d in zip(mod_headings, mod_dicts):\n",
    "    print('\\n' + h + ':')\n",
    "    for (k, v) in d.items():\n",
    "        print(k + ': ' + str(v))     \n",
    "\n",
    "# Uncomment to view data and to debug        \n",
    "# print('\\n')\n",
    "# print(pacounter)\n",
    "# print('\\n')\n",
    "# print(lscounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With numbers in hand, we prepare data structures to use in visualization and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For graphing and other analysis, we need to create portable, persistent data structures.\n",
    "# We will do this by creating a list of lists, each list comprising the key/value pairs from one dictionary. \n",
    "# Then we will sort each of those lists and add each to a list of sorted lists\n",
    "\n",
    "# Initialize the lists - unsorted and sorted (the dicts have been created above). \n",
    "# Name each list for the dictionary it will be drawn from.\n",
    "ccount, dcount, pcount, cacount, scount, rcount, cocount, pacount, lscount = [[],[],[],[],[],[],[],[],[]]\n",
    "sccount, sdcount, spcount, scacount, sscount, srcount, scocount, spacount, slscount = [[],[],[],[],[],[],[],[],[]]  # 's' for sorted\n",
    "\n",
    "# Create containers with the names of our dicts and lists so we can do all the processing in a loop\n",
    "dcts = [ccounter, dcounter, pcounter, cacounter, scounter, rcounter, cocounter, pacounter, lscounter]\n",
    "lsts = [ccount, dcount, pcount, cacount, scount, rcount, cocount, pacount, lscount]\n",
    "srtdlsts = [sccount, sdcount, spcount, scacount, sscount, srcount, scocount, spacount, slscount]\n",
    "\n",
    "# For each dictionary item, append the key/value pair as a tuple to the named list related to the dictionary\n",
    "for d, l, s in zip(dcts, lsts, srtdlsts):\n",
    "    for key in d.keys():\n",
    "        tup = (key, d[key])\n",
    "        l.append(tup)\n",
    "    # Sort each list by the second element in each tuple (the value of the original key/value pair) and add\n",
    "    # the sorted list to list of sorted lists\n",
    "    s.extend(sorted(l, key=lambda x: x[1], reverse=True))  # reverse means descending order\n",
    "    \n",
    "# Uncomment the next lines view data on screen    \n",
    "# for lst in lsts:\n",
    "#     print(lst)\n",
    "#     print('\\n')\n",
    "# for srtdlst in srtdlsts:\n",
    "#     print(srtdlst)\n",
    "#     print('\\n')\n",
    "\n",
    "# Uncomment these print commands to review individual lists by name\n",
    "# print(str(ccount) + '\\n')\n",
    "# print(str(dcount) + '\\n')\n",
    "# print(str(pcount) + '\\n')\n",
    "# print(str(cacount) + '\\n')\n",
    "# print(str(scount) + '\\n')\n",
    "# print(str(rcount) + '\\n')\n",
    "# print(str(cocount) + '\\n')\n",
    "# print(str(pacount) + '\\n')\n",
    "# print(str(lscount) + '\\n')\n",
    "# print(str(sccount) + '\\n')\n",
    "# print(str(sdcount) + '\\n')\n",
    "# print(str(spcount) + '\\n')\n",
    "# print(str(scacount) + '\\n')\n",
    "# print(str(sscount) + '\\n')\n",
    "# print(str(srcount) + '\\n')\n",
    "# print(str(scocount) + '\\n')\n",
    "# print(str(spacount) + '\\n')\n",
    "# print(str(slscount) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we write these to a file? (Of course we can.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Create a filename with a simple timestamp so we don't overwrite file each time we write.\n",
    "basename = 'rdm_tabulations_'\n",
    "datestr = str(datetime.today())\n",
    "datestr = datestr[:-7]   # Remove microseconds\n",
    "datestr = datestr.replace(' ', 'T')  # Replace space with 'T' so filename doesn't cause problems elsewhere\n",
    "datestr = datestr.replace(':','-')  # The colons in the timestamp may cause problems, so swap them out, too\n",
    "fileoutname = 'rdm_tabulations_' + datestr + '.txt'\n",
    "#print(filename) #debug\n",
    "\n",
    "with open(fileoutname, 'w') as f:\n",
    "    \n",
    "    f.write('\\nIn %s, RDM Consulting provided %d consultations.\\n\\n' % (report_period_descriptor, (len(myrows))))\n",
    "    \n",
    "    for lst, hdr in zip(srtdlsts,all_headings):\n",
    "        h = hdr\n",
    "        f.write(h + ':\\n\\n')\n",
    "        for item in lst:\n",
    "            k = item[0]\n",
    "            v = item[1]\n",
    "            f.write(k + ': ' + str(v))\n",
    "            f.write('\\n')\n",
    "        f.write('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot pie charts for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pie charts of each category, where the slices will be ordered and plotted counter-clockwise:\n",
    "\n",
    "for s in srtdlsts:\n",
    "    \n",
    "    labels = []\n",
    "    sizes = []\n",
    "    labelsplusn = []\n",
    "    \n",
    "    for pair in s:\n",
    "        labels.append(pair[0])\n",
    "        sizes.append(pair[1])\n",
    "\n",
    "    #print(labels) #debug\n",
    "    #print(sizes)  #debug\n",
    "    \n",
    "    for label, size in zip(labels, sizes):\n",
    "        labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "        labelsplusn.append(labelplusn)\n",
    "    \n",
    "    #print(labelsplusn)  #debug\n",
    "    \n",
    "    explode = [.1 for _ in range(len(s))]  # one value for each element in len(sortedlist)\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=37)  # originally labels=labels\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "    plt.show()\n",
    "    #print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of cells generate each pie chart separately so we can customize them. \n",
    "\n",
    "NOTE: These need to be customized based on the date range: the number of arguments in the statement 'explode = ()'\n",
    "must be equal to the number of items in the sorted list, and that will vary depending upon the range of time covered by the reporting period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pie chart of schools, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in spacount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "#print(len(labels))\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "    \n",
    "explode = (.3, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .2, .3, .4, .5,  .6, .7, .8, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=37)  # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_spacount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of schools with all L&S combined, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in slscount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "#print(len(labels))\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.2, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .3, .4, .5,  .6, .7, .8, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=37)  #originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_slscount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of original department/oru values, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in sdcount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (2.1, 1.9, 1.9, 1.8, 1.9, 2.1, 2.3, 2.5, 2.7, 2.9, 3.1, 3.3, 3.5, 3.7, 3.9, 4.3, 4.7, 5.1, 5.5, 10.1, 9.7, 9.5, 9.3, 9.1, 8.9, 8.7, 8.5, 8.3, 8.1, 7.9, 7.7, 7.5, 7.3, 7.1, 6.9, 6.7, 6.5, 6.3, 6.1, 5.9, 5.7, 5.5, 5.3, 5.1, 4.9, 4.7, 4.5, 4.3, 4.1, 3.9, 2.1, 2.3,  2.5, 2.7, 2.9, 3.1, 3.3, 3.5, 3.7, .8, .8, .8, .9, .9, .9, .9, .9, .9, .9, .9, .9, .9, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_sdcount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of position of client on campus, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in spcount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .2, .3, .4, .5, .6, .7, .8, .9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_spcount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of (RDM Lifecycle) category, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in scacount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "# print(labels) #debug\n",
    "# print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .2, .3, .4, .5, .6, .7, .8, .9, )  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_scacount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of sources (referrals in), where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in sscount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "# print(labels) #debug\n",
    "# print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1, .1, .1, .1, .2, .3, .4, .5, .6, .7, .8, .9)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_sscount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of referrals out, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in srcount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "# print(labels) #debug\n",
    "# print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=50) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_srcount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of complexity measures, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = []\n",
    "sizes = []\n",
    "labelsplusn = []\n",
    "\n",
    "for pair in scocount:\n",
    "    labels.append(pair[0])\n",
    "    sizes.append(pair[1])\n",
    "#print(labels) #debug\n",
    "#print(sizes)  #debug\n",
    "\n",
    "for label, size in zip(labels, sizes):\n",
    "    labelplusn = str(label) + ' (' + str(size) + ')'\n",
    "    labelsplusn.append(labelplusn)\n",
    "\n",
    "#print(labelsplusn)  #debug\n",
    "\n",
    "explode = (.1, .1, .1, .1)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labelsplusn, autopct='%1.f%%',\n",
    "        shadow=True, startangle=40) # originally labels=labels\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('pie_scocount.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top five values in each category (or all values, if less than five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lst, hdr in zip(srtdlsts, all_headings):\n",
    "    print('\\n' + 'Top Five: ' + hdr)\n",
    "    for i in range(5):\n",
    "        if i >= len(lst): continue\n",
    "        (k,v) = lst[i]\n",
    "        print(str(i+1) + '. ' + k + ': ' + str(v))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
